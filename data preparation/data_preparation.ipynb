{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "\n",
    "I will follow the steps outlined in *\"Parameter estimation of the MFD: a maximum likelihood approach\"*.  \n",
    "\n",
    "First, the following cities will be left out:\n",
    "- Paris (1h intervals, too aggregated)\n",
    "- Bolton, Birmingham, Groningen, Innsbruck, Manchester, Melbourne, Rotterdam, Torino, Utrecht (partial or no occupancy measurements)\n",
    "\n",
    "**Step 1: Load raw data and remove selected cities from the two data sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data from raw data folder\n",
    "# we will specify the data types for each column to save memory and prevent errors\n",
    "dtype_dict = {\n",
    "    'day': 'str',  # Assuming day is an integer\n",
    "    'interval': 'int32',  # Assuming interval is an integer\n",
    "    'detid': 'str',  # Treat detid as a string to avoid mixed types\n",
    "    'flow': 'float32',  # Assuming flow is a decimal number\n",
    "    'occ': 'float32',  # Assuming occ is a decimal number\n",
    "    'error': 'float32',  # Assuming error is a decimal number\n",
    "    'city': 'category',  # Assuming city names are repeated, use 'category' for memory efficiency\n",
    "    'speed': 'float32'  # Assuming speed is a decimal number\n",
    "}\n",
    "\n",
    "data = pd.read_csv('C:/DTU/Speciale/Kode/Speciale/data/raw/utd19_u.csv', dtype=dtype_dict)\n",
    "\n",
    "# Parse the day column as a datetime object\n",
    "data['day'] = pd.to_datetime(data['day'], format='%Y-%m-%d')\n",
    "\n",
    "detector = pd.read_csv('C:/DTU/Speciale/Kode/Speciale/data/raw/detectors_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>interval</th>\n",
       "      <th>detid</th>\n",
       "      <th>flow</th>\n",
       "      <th>occ</th>\n",
       "      <th>error</th>\n",
       "      <th>city</th>\n",
       "      <th>speed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>0</td>\n",
       "      <td>06.X-2li</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>300</td>\n",
       "      <td>06.X-2li</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>600</td>\n",
       "      <td>06.X-2li</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>900</td>\n",
       "      <td>06.X-2li</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>1200</td>\n",
       "      <td>06.X-2li</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134380366</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>85500</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134380367</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>85680</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134380368</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>85860</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134380369</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>86040</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134380370</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>86220</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>134380371 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 day  interval     detid   flow       occ  error      city  \\\n",
       "0         2017-05-06         0  06.X-2li   12.0  0.000000    1.0  augsburg   \n",
       "1         2017-05-06       300  06.X-2li   12.0  0.000000    1.0  augsburg   \n",
       "2         2017-05-06       600  06.X-2li   12.0  0.000000    1.0  augsburg   \n",
       "3         2017-05-06       900  06.X-2li   16.0  0.000000    1.0  augsburg   \n",
       "4         2017-05-06      1200  06.X-2li   16.0  0.000000    1.0  augsburg   \n",
       "...              ...       ...       ...    ...       ...    ...       ...   \n",
       "134380366 2015-11-01     85500     K8D20  120.0  0.015556    0.0    zurich   \n",
       "134380367 2015-11-01     85680     K8D20  120.0  0.017778    0.0    zurich   \n",
       "134380368 2015-11-01     85860     K8D20  120.0  0.014444    0.0    zurich   \n",
       "134380369 2015-11-01     86040     K8D20  200.0  0.028333    0.0    zurich   \n",
       "134380370 2015-11-01     86220     K8D20  180.0  0.024444    0.0    zurich   \n",
       "\n",
       "           speed  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "...          ...  \n",
       "134380366    NaN  \n",
       "134380367    NaN  \n",
       "134380368    NaN  \n",
       "134380369    NaN  \n",
       "134380370    NaN  \n",
       "\n",
       "[134380371 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detid</th>\n",
       "      <th>length</th>\n",
       "      <th>pos</th>\n",
       "      <th>fclass</th>\n",
       "      <th>road</th>\n",
       "      <th>limit</th>\n",
       "      <th>citycode</th>\n",
       "      <th>lanes</th>\n",
       "      <th>linkid</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U1-52G</td>\n",
       "      <td>0.196037</td>\n",
       "      <td>0.005512</td>\n",
       "      <td>secondary</td>\n",
       "      <td>Gögginger Straße</td>\n",
       "      <td>50</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>10.889553</td>\n",
       "      <td>48.359957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>U1-51G</td>\n",
       "      <td>0.130039</td>\n",
       "      <td>0.004013</td>\n",
       "      <td>secondary</td>\n",
       "      <td>Gögginger Straße</td>\n",
       "      <td>50</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>10.889601</td>\n",
       "      <td>48.359945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>U1-52L</td>\n",
       "      <td>0.155863</td>\n",
       "      <td>0.022228</td>\n",
       "      <td>secondary</td>\n",
       "      <td>Gögginger Straße</td>\n",
       "      <td>50</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>10.889356</td>\n",
       "      <td>48.359876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U1-51L</td>\n",
       "      <td>0.197675</td>\n",
       "      <td>0.021889</td>\n",
       "      <td>secondary</td>\n",
       "      <td>Gögginger Straße</td>\n",
       "      <td>50</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>10.889396</td>\n",
       "      <td>48.359862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U1-62</td>\n",
       "      <td>0.065183</td>\n",
       "      <td>0.024465</td>\n",
       "      <td>secondary</td>\n",
       "      <td>Rosenaustraße</td>\n",
       "      <td>50</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>1.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>10.889361</td>\n",
       "      <td>48.360578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    detid    length       pos     fclass              road limit  citycode  \\\n",
       "0  U1-52G  0.196037  0.005512  secondary  Gögginger Straße    50  augsburg   \n",
       "1  U1-51G  0.130039  0.004013  secondary  Gögginger Straße    50  augsburg   \n",
       "2  U1-52L  0.155863  0.022228  secondary  Gögginger Straße    50  augsburg   \n",
       "3  U1-51L  0.197675  0.021889  secondary  Gögginger Straße    50  augsburg   \n",
       "4   U1-62  0.065183  0.024465  secondary     Rosenaustraße    50  augsburg   \n",
       "\n",
       "   lanes  linkid       long        lat  \n",
       "0    1.0    72.0  10.889553  48.359957  \n",
       "1    1.0    73.0  10.889601  48.359945  \n",
       "2    1.0    70.0  10.889356  48.359876  \n",
       "3    1.0    71.0  10.889396  48.359862  \n",
       "4    1.0    68.0  10.889361  48.360578  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detector.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling of Los Angeles in detector df to match data df\n",
    "# change from losanageles to losangeles\n",
    "detector['citycode'] = detector['citycode'].replace('losanageles', 'losangeles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Code for checking if the cities in the two dataframes are the same\n",
    "# data_cities = data['city'].unique()\n",
    "# detector_cities = detector['citycode'].unique()\n",
    "# print(data_cities)\n",
    "# print(detector_cities)\n",
    "# # check if the two sets of cities are the same, print diffqerences if not\n",
    "# if set(data_cities) != set(detector_cities):\n",
    "#     print('Cities in data but not in detector: ', set(data_cities) - set(detector_cities))\n",
    "#     print('Cities in detector but not in data: ', set(detector_cities) - set(data_cities))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to remove the following cities from the data\n",
    "# As the aggregation level is too high \n",
    "delete_cities_1 = ['paris']\n",
    "# or they have partial or no occupancy data\n",
    "delete_cities_2 = ['birmingham', 'bolton', 'groningen', 'innsbruck', 'manchester', 'melbourne', 'rotterdam', 'torino', 'utrecht']\n",
    "# present in the detector data but not in the data\n",
    "delete_cities_3 = ['tokyo']\n",
    "\n",
    "# Remove the cities from the data\n",
    "data = data[~data['city'].isin(delete_cities_1 + delete_cities_2 + delete_cities_3)]\n",
    "detector = detector[~detector['citycode'].isin(delete_cities_1 + delete_cities_2 + delete_cities_3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Criteria for discarding observations**\n",
    "\n",
    "The following type of observations are considereed to be outliers or faulty, and will now be discarded from the data set:\n",
    "- Values marked as errors in the observations data set\n",
    "- Occupancy measurements larger than 1\n",
    "- Flow measurements larger than 2500 veh/hr/ln\n",
    "- Flow measurements less than 10 veh/hr/ln for occupancy values between 0.2 and 0.75\n",
    "- Flow measurements higher than 100 veh/hr/ln for occupancy values larger than 0.95 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error\n",
      "NaN    52673887\n",
      "1.0    44438436\n",
      "0.0    29074904\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#######------- We notice that there's a lot of observations with an unclear´\n",
    "#######------- error destription NaN. We assume they're not errenuous\n",
    "# Get the number of rows with error values = 1\n",
    "error_counts = data['error'].value_counts(dropna=False)\n",
    "print(error_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove values marked as errors in the observations data set\n",
    "# i.e. drop rows with error = 1\n",
    "data = data[data['error'] != 1]\n",
    "\n",
    "# Remove occupancy measurements larger than 1\n",
    "data = data[data['occ'] <= 1]\n",
    "\n",
    "# Remove flow measurements larger than 2500 veh/hr/ln\n",
    "data = data[data['flow'] <= 2500]\n",
    "\n",
    "# Remove flow measurements less than 10 veh/hr/ln for occupancy values between 0.2 and 0.75\n",
    "data = data[~((data['flow'] < 10) & (data['occ'] > 0.2) & (data['occ'] < 0.75))]\n",
    "\n",
    "# Remove flow measurements less than 10 veh/hr/ln for occupancy values between 0.2 and 0.75\n",
    "data = data[~((data['flow'] < 10) & (data['occ'] > 0.2) & (data['occ'] < 0.75))]\n",
    "\n",
    "# Remove flow measurements higher than 100 veh/hr/ln for occupancy values larger than 0.95\n",
    "data = data[~((data['flow'] > 100) & (data['occ'] > 0.95))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Select only the loop detectors with valid data for more than 80% of the time intervals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine date and interval columns to create unique timestamps\n",
    "data['timestamp'] = data['day'] + pd.to_timedelta(data['interval'], unit='h')\n",
    "# Create a new column 'day_interval' combining 'day' and 'interval'\n",
    "# data['day_interval'] = data['day'].astype(str) + '-' + data['interval'].astype(str).str.zfill(5)\n",
    "#---- decide which is better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the loop detectors with valid data for more than 80% of the time intervals\n",
    "\n",
    "# Create empty list to store the filtered data\n",
    "filtered_data_list = []\n",
    "# Create empty list to store statistics for each city\n",
    "stats_list = []\n",
    "\n",
    "# Get all the city names\n",
    "cities = data['city'].unique()\n",
    "\n",
    "for city in cities:\n",
    "    # Get the data for the city\n",
    "    city_data = data[data['city'] == city]\n",
    "\n",
    "    # Get the number of time intervals in the data\n",
    "    n_intervals = city_data['timestamp'].nunique()\n",
    "\n",
    "    # Get the number of valid observations for each detector\n",
    "    detector_counts = city_data['detid'].value_counts()\n",
    "\n",
    "    # Get the detectors with more than 80% valid observations\n",
    "    valid_detectors = detector_counts[detector_counts > 0.8 * n_intervals].index\n",
    "\n",
    "    # Filter the data for the valid detectors\n",
    "    city_data = city_data[city_data['detid'].isin(valid_detectors)]\n",
    "\n",
    "    # Append the filtered data   \n",
    "    filtered_data_list.append(city_data)\n",
    "\n",
    "    # Save the number of detectors, intervals, etc. for each city\n",
    "    total_detectors = len(detector_counts)\n",
    "    valid_detector_count = len(valid_detectors)\n",
    "    valid_percentage = valid_detector_count / total_detectors * 100\n",
    "\n",
    "    # Append the statistics to the list\n",
    "    stats_list.append({\n",
    "        'city': city,\n",
    "        'total_detectors': total_detectors,\n",
    "        'valid_detectors': valid_detector_count,\n",
    "        'valid_percentage': valid_percentage,\n",
    "        'total_intervals': n_intervals,\n",
    "    })\n",
    "\n",
    "# Combine all the filtered data into a single DataFrame at once\n",
    "filtered_data = pd.concat(filtered_data_list, ignore_index=True)\n",
    "\n",
    "# Create a DataFrame from the statistics list\n",
    "stats_df = pd.DataFrame(stats_list)\n",
    "\n",
    "# Check the final filtered DataFrame\n",
    "# print(filtered_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city  total_detectors  valid_detectors  valid_percentage  \\\n",
      "0     augsburg              454              106         23.348018   \n",
      "1        basel               60               50         83.333333   \n",
      "2         bern              471              294         62.420382   \n",
      "3     bordeaux              320              254         79.375000   \n",
      "4       bremen              480              352         73.333333   \n",
      "5     cagliari               98               96         97.959184   \n",
      "6    constance               92               77         83.695652   \n",
      "7    darmstadt              208              127         61.057692   \n",
      "8        essen               36               36        100.000000   \n",
      "9    frankfurt               73               73        100.000000   \n",
      "10        graz              246              187         76.016260   \n",
      "11     hamburg              325              273         84.000000   \n",
      "12      kassel              434              367         84.562212   \n",
      "13      london             4762             2620         55.018900   \n",
      "14  losangeles             1685              353         20.949555   \n",
      "15      luzern              140              131         93.571429   \n",
      "16      madrid             1008              766         75.992063   \n",
      "17   marseille              156              150         96.153846   \n",
      "18      munich              358              352         98.324022   \n",
      "19   santander              204              178         87.254902   \n",
      "20      speyer              139              107         76.978417   \n",
      "21  strasbourg              142              141         99.295775   \n",
      "22   stuttgart              211              149         70.616114   \n",
      "23      taipeh              370              252         68.108108   \n",
      "24     toronto              163              113         69.325153   \n",
      "25    toulouse              469              296         63.113006   \n",
      "26     vilnius              468              147         31.410256   \n",
      "27   wolfsburg              107               64         59.813084   \n",
      "28      zurich             1020             1019         99.901961   \n",
      "\n",
      "    total_intervals  \n",
      "0              5757  \n",
      "1              2015  \n",
      "2              2015  \n",
      "3              2016  \n",
      "4              6720  \n",
      "5              7294  \n",
      "6              2016  \n",
      "7              6517  \n",
      "8              6360  \n",
      "9               288  \n",
      "10             2880  \n",
      "11             7378  \n",
      "12             1146  \n",
      "13             5961  \n",
      "14             2557  \n",
      "15             7900  \n",
      "16             3875  \n",
      "17             7229  \n",
      "18              288  \n",
      "19             2041  \n",
      "20             6720  \n",
      "21             6397  \n",
      "22             2304  \n",
      "23             6620  \n",
      "24             5580  \n",
      "25             3360  \n",
      "26              481  \n",
      "27             6720  \n",
      "28             3359  \n"
     ]
    }
   ],
   "source": [
    "print(stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Keep only intervals with valid data for more than 80% of the previously selected loop detectors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only intervals with valid data for more than 80% of the previously selected loop detectors\n",
    "\n",
    "# Create empty list to store the filtered data\n",
    "filtered_data_list = []\n",
    "# Create empty list to store statistics for each city\n",
    "city_stats_list = []\n",
    "\n",
    "# Get all the city names\n",
    "cities = filtered_data['city'].unique()\n",
    "\n",
    "for city in cities:\n",
    "    # Get the data for the city\n",
    "    city_data = filtered_data[filtered_data['city'] == city]\n",
    "\n",
    "    # Get the number of time intervals in the data\n",
    "    n_intervals = city_data['timestamp'].nunique()\n",
    "\n",
    "    # Get the number of valid observations for each time interval\n",
    "    interval_counts = city_data['timestamp'].value_counts()\n",
    "\n",
    "    # Get the intervals with more than 80% valid observations\n",
    "    valid_intervals = interval_counts[interval_counts > 0.8 * len(city_data['detid'].unique())].index\n",
    "\n",
    "    # Filter the data for the valid intervals\n",
    "    city_data = city_data[city_data['timestamp'].isin(valid_intervals)]\n",
    "\n",
    "    # Append the filtered data\n",
    "    filtered_data_list.append(city_data)\n",
    "\n",
    "    # Save the number of intervals, etc. for each city\n",
    "    total_intervals = len(interval_counts)\n",
    "    valid_interval_count = len(valid_intervals)\n",
    "    valid_percentage = valid_interval_count / total_intervals * 100\n",
    "\n",
    "    # Append the statistics to the list\n",
    "    city_stats_list.append({\n",
    "        'city': city,\n",
    "        'total_intervals': total_intervals,\n",
    "        'valid_intervals': valid_interval_count,\n",
    "        'valid_percentage': valid_percentage,\n",
    "        'total_detectors': len(city_data['detid'].unique()),\n",
    "    })\n",
    "\n",
    "# Combine all the filtered data into a single DataFrame at once\n",
    "filtered_data = pd.concat(filtered_data_list, ignore_index=True)\n",
    "\n",
    "# Create a DataFrame from the statistics list\n",
    "city_stats_df = pd.DataFrame(city_stats_list)\n",
    "\n",
    "# Check the final filtered DataFrame\n",
    "# print(filtered_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city  total_intervals  valid_intervals  valid_percentage  \\\n",
      "0     augsburg             5757             4605         79.989578   \n",
      "1        basel             2015             2015        100.000000   \n",
      "2         bern             2015             1739         86.302730   \n",
      "3     bordeaux             2016             1689         83.779762   \n",
      "4       bremen             6720             5760         85.714286   \n",
      "5     cagliari             7294             7294        100.000000   \n",
      "6    constance             2016             2016        100.000000   \n",
      "7    darmstadt             6517             6310         96.823692   \n",
      "8        essen             6360             6286         98.836478   \n",
      "9    frankfurt              288              287         99.652778   \n",
      "10        graz             2880             2515         87.326389   \n",
      "11     hamburg             7378             7355         99.688262   \n",
      "12      kassel             1146              975         85.078534   \n",
      "13      london             5961             5701         95.638316   \n",
      "14  losangeles             2557             2050         80.172077   \n",
      "15      luzern             7900             7847         99.329114   \n",
      "16      madrid             3875             2688         69.367742   \n",
      "17   marseille             7229             7227         99.972334   \n",
      "18      munich              288              231         80.208333   \n",
      "19   santander             2041             1958         95.933366   \n",
      "20      speyer             6720             6611         98.377976   \n",
      "21  strasbourg             6397             6397        100.000000   \n",
      "22   stuttgart             2304             1970         85.503472   \n",
      "23      taipeh             6620             6514         98.398792   \n",
      "24     toronto             5580             5475         98.118280   \n",
      "25    toulouse             3360             2511         74.732143   \n",
      "26     vilnius              481              352         73.180873   \n",
      "27   wolfsburg             6720             6720        100.000000   \n",
      "28      zurich             3359             3354         99.851146   \n",
      "\n",
      "    total_detectors  \n",
      "0               106  \n",
      "1                50  \n",
      "2               294  \n",
      "3               254  \n",
      "4               352  \n",
      "5                96  \n",
      "6                77  \n",
      "7               127  \n",
      "8                36  \n",
      "9                73  \n",
      "10              187  \n",
      "11              273  \n",
      "12              367  \n",
      "13             2620  \n",
      "14              353  \n",
      "15              131  \n",
      "16              766  \n",
      "17              150  \n",
      "18              352  \n",
      "19              178  \n",
      "20              107  \n",
      "21              141  \n",
      "22              149  \n",
      "23              252  \n",
      "24              113  \n",
      "25              296  \n",
      "26              147  \n",
      "27               64  \n",
      "28             1019  \n"
     ]
    }
   ],
   "source": [
    "print(city_stats_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Save a filtered version of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the filtered data to a CSV file\n",
    "# filtered_data.to_csv('C:/DTU/Speciale/Kode/Speciale/data/processed/filtered_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Merge the data sets on detector ID**\n",
    "\n",
    "The two data sets will be merged on city and detid (some detid's repeat between cities)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the name of the column 'citycode' to 'city' in the detector data\n",
    "detector.rename(columns={'citycode': 'city'}, inplace=True)\n",
    "\n",
    "# Merge the filtered data with the detector data\n",
    "merged_data = pd.merge(filtered_data, detector, on=['city', 'detid'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Save the merged data to a CSV file\n",
    "# merged_data.to_csv('C:/DTU/Speciale/Kode/Speciale/data/processed/merged_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day</th>\n",
       "      <th>interval</th>\n",
       "      <th>detid</th>\n",
       "      <th>flow</th>\n",
       "      <th>occ</th>\n",
       "      <th>error</th>\n",
       "      <th>city</th>\n",
       "      <th>speed</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>length</th>\n",
       "      <th>pos</th>\n",
       "      <th>fclass</th>\n",
       "      <th>road</th>\n",
       "      <th>limit</th>\n",
       "      <th>lanes</th>\n",
       "      <th>linkid</th>\n",
       "      <th>long</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>0</td>\n",
       "      <td>12-1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-06 00:00:00</td>\n",
       "      <td>0.264448</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>primary</td>\n",
       "      <td>Berliner Allee</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>10.928206</td>\n",
       "      <td>48.365476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>300</td>\n",
       "      <td>12-1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-18 12:00:00</td>\n",
       "      <td>0.264448</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>primary</td>\n",
       "      <td>Berliner Allee</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>10.928206</td>\n",
       "      <td>48.365476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>600</td>\n",
       "      <td>12-1</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-05-31 00:00:00</td>\n",
       "      <td>0.264448</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>primary</td>\n",
       "      <td>Berliner Allee</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>10.928206</td>\n",
       "      <td>48.365476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>900</td>\n",
       "      <td>12-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-06-12 12:00:00</td>\n",
       "      <td>0.264448</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>primary</td>\n",
       "      <td>Berliner Allee</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>10.928206</td>\n",
       "      <td>48.365476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-05-06</td>\n",
       "      <td>1200</td>\n",
       "      <td>12-1</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>augsburg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2017-06-25 00:00:00</td>\n",
       "      <td>0.264448</td>\n",
       "      <td>0.042628</td>\n",
       "      <td>primary</td>\n",
       "      <td>Berliner Allee</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>409.0</td>\n",
       "      <td>10.928206</td>\n",
       "      <td>48.365476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66998425</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>85500</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-08-02 12:00:00</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.205066</td>\n",
       "      <td>primary</td>\n",
       "      <td>Seebahnstrasse</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>8.521908</td>\n",
       "      <td>47.372198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66998426</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>85680</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.017778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-08-10 00:00:00</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.205066</td>\n",
       "      <td>primary</td>\n",
       "      <td>Seebahnstrasse</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>8.521908</td>\n",
       "      <td>47.372198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66998427</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>85860</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-08-17 12:00:00</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.205066</td>\n",
       "      <td>primary</td>\n",
       "      <td>Seebahnstrasse</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>8.521908</td>\n",
       "      <td>47.372198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66998428</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>86040</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-08-25 00:00:00</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.205066</td>\n",
       "      <td>primary</td>\n",
       "      <td>Seebahnstrasse</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>8.521908</td>\n",
       "      <td>47.372198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66998429</th>\n",
       "      <td>2015-11-01</td>\n",
       "      <td>86220</td>\n",
       "      <td>K8D20</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.024444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>zurich</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-01 12:00:00</td>\n",
       "      <td>0.235968</td>\n",
       "      <td>0.205066</td>\n",
       "      <td>primary</td>\n",
       "      <td>Seebahnstrasse</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>8.521908</td>\n",
       "      <td>47.372198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>66998430 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                day  interval  detid   flow       occ  error      city  speed  \\\n",
       "0        2017-05-06         0   12-1  104.0  0.010000    NaN  augsburg    NaN   \n",
       "1        2017-05-06       300   12-1  104.0  0.010000    NaN  augsburg    NaN   \n",
       "2        2017-05-06       600   12-1  104.0  0.010000    NaN  augsburg    NaN   \n",
       "3        2017-05-06       900   12-1   88.0  0.020000    NaN  augsburg    NaN   \n",
       "4        2017-05-06      1200   12-1   88.0  0.020000    NaN  augsburg    NaN   \n",
       "...             ...       ...    ...    ...       ...    ...       ...    ...   \n",
       "66998425 2015-11-01     85500  K8D20  120.0  0.015556    0.0    zurich    NaN   \n",
       "66998426 2015-11-01     85680  K8D20  120.0  0.017778    0.0    zurich    NaN   \n",
       "66998427 2015-11-01     85860  K8D20  120.0  0.014444    0.0    zurich    NaN   \n",
       "66998428 2015-11-01     86040  K8D20  200.0  0.028333    0.0    zurich    NaN   \n",
       "66998429 2015-11-01     86220  K8D20  180.0  0.024444    0.0    zurich    NaN   \n",
       "\n",
       "                   timestamp    length       pos   fclass            road  \\\n",
       "0        2017-05-06 00:00:00  0.264448  0.042628  primary  Berliner Allee   \n",
       "1        2017-05-18 12:00:00  0.264448  0.042628  primary  Berliner Allee   \n",
       "2        2017-05-31 00:00:00  0.264448  0.042628  primary  Berliner Allee   \n",
       "3        2017-06-12 12:00:00  0.264448  0.042628  primary  Berliner Allee   \n",
       "4        2017-06-25 00:00:00  0.264448  0.042628  primary  Berliner Allee   \n",
       "...                      ...       ...       ...      ...             ...   \n",
       "66998425 2025-08-02 12:00:00  0.235968  0.205066  primary  Seebahnstrasse   \n",
       "66998426 2025-08-10 00:00:00  0.235968  0.205066  primary  Seebahnstrasse   \n",
       "66998427 2025-08-17 12:00:00  0.235968  0.205066  primary  Seebahnstrasse   \n",
       "66998428 2025-08-25 00:00:00  0.235968  0.205066  primary  Seebahnstrasse   \n",
       "66998429 2025-09-01 12:00:00  0.235968  0.205066  primary  Seebahnstrasse   \n",
       "\n",
       "         limit  lanes  linkid       long        lat  \n",
       "0           50    1.0   409.0  10.928206  48.365476  \n",
       "1           50    1.0   409.0  10.928206  48.365476  \n",
       "2           50    1.0   409.0  10.928206  48.365476  \n",
       "3           50    1.0   409.0  10.928206  48.365476  \n",
       "4           50    1.0   409.0  10.928206  48.365476  \n",
       "...        ...    ...     ...        ...        ...  \n",
       "66998425    50    1.0   199.0   8.521908  47.372198  \n",
       "66998426    50    1.0   199.0   8.521908  47.372198  \n",
       "66998427    50    1.0   199.0   8.521908  47.372198  \n",
       "66998428    50    1.0   199.0   8.521908  47.372198  \n",
       "66998429    50    1.0   199.0   8.521908  47.372198  \n",
       "\n",
       "[66998430 rows x 18 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
